{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCXJW8ZdLtK1"
   },
   "source": [
    "# Faire - The Online Wholesale Marketplace & Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e88SjvpgLtK2"
   },
   "source": [
    "Welcome! Lets build a new search ranking model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQmR6dCcLtK3"
   },
   "source": [
    "### Description\n",
    "\n",
    "Knowing whether a Product in Search will be bought in advance could provide huge business value to Faire. This task is very important for purchase prediction as well as for short term user engagement prediction.\n",
    "\n",
    "- In this dataset we have sampled ~20k rows from Faire search logs. The dataset is anonymized. Before describing the dataset, lets give some preliminary knowledge of how Faire Wholesale MarketPlace Search works. Faire is a two-sided marketplace where retailers come to shop wholesale products from brands. When a retailer makes a search on the site, we call that a search request. The response is a page with many products. We assign a `request_id` to this search request response, and different pages (page number 1, 2, 3...) from the same search have different `request_id`s (i.e. `request_id` is more of a \"page id\" than a \"search session id\"). Each row in this dataset represents one single product that was impressed for that `request_id`. For each request_id you can have many results (due to this being a random sample some of them might be missed in a some cases). \n",
    "\n",
    "- Each row contains the following fields: `request_id`, `retailer_token` (anonymzed user token), `query_text` (the actual search string), `page_number`, `page_size`, `position`, `filter_string` (filters applied on top of the search), `has_product_click` (was it clicked or not). \n",
    "- We have some features from our feature store (computed using data from before the search timestamp): anything starting with `product.` is a product-level feature. We have also a few personalization features in this dataset, anything starting with `retailerbrand.` is a personalization feature and relates to a particular retailer:brand pair. \n",
    "- Note that we have personalization features only at the level of retailer(user) and the brand the product belongs to. Brands usually have many products in our marketplace, so Product <-> Brand mapping is Many:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQmR6dCcLtK3"
   },
   "source": [
    "### Tasks\n",
    "In approximately 1 hour, please do the following:\n",
    "- Please build first a ranking model using the provided dataset and evaluate it. \n",
    "- If there is time, please implement 1 or 2 additional features, and list up to 10 more features (without implementing them).\n",
    "- If there is time, please give us an idea of the next steps, how would you improve this model if you had 1 week more, 1 month more, or 3 months more?\n",
    "\n",
    "Please write as many comments or communicate out loud your thought process. Once your time allocation is up, please send back the completed notebook in .ipynb and .pdf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1603217376889,
     "user": {
      "displayName": "Ildus Ahmadullin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaB9bqpJm6HE2WR6lDP6dLFHKsS3SpXHFabinl=s64",
      "userId": "02756298952784264409"
     },
     "user_tz": 420
    },
    "id": "c821NPAOLtK3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 405,
     "status": "error",
     "timestamp": 1603217749887,
     "user": {
      "displayName": "Ildus Ahmadullin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaB9bqpJm6HE2WR6lDP6dLFHKsS3SpXHFabinl=s64",
      "userId": "02756298952784264409"
     },
     "user_tz": 420
    },
    "id": "7eOmQIatMwca",
    "outputId": "69099e62-51d2-4a04-914e-bead825406c3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/faire-ml-rank-small.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_title(row):\n",
    "    if row['query_text'] in row['title']:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def match_desc(row):\n",
    "    if row['query_text'] in row['description']:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "data['description'] = data['description'].fillna(\"\")\n",
    "data['title_match'] = data.apply(match_title, axis=1)\n",
    "data['description_match'] = data.apply(match_desc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not needed\n",
    "features = data.drop(\n",
    "    ['Unnamed: 0.1', 'Unnamed: 0', 'rand', 'title', 'description', 'created_at_a', 'query_text','filter_string', 'retailer_token_anon', 'product.product_is_high_sell_through'],\n",
    "    axis=1\n",
    ")\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ignore_columns = {'request_id_anon', 'has_product_click'}\n",
    "features = features.fillna(0.0)\n",
    "scaler = StandardScaler()\n",
    "for column in features.columns:\n",
    "    if column in ignore_columns:\n",
    "        continue\n",
    "    scaler = StandardScaler()\n",
    "    features[column] = scaler.fit_transform(features[[column]])    \n",
    "\n",
    "features['has_product_click'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "request_ids = features['request_id_anon'].unique()\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "r_train, r_test = train_test_split(request_ids, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "# r_train.shape, r_test.shape\n",
    "X_train = features[features['request_id_anon'].isin(r_train)].drop(['request_id_anon'], axis=1)\n",
    "X_test = features[features['request_id_anon'].isin(r_test)].drop(['request_id_anon'], axis=1)\n",
    "\n",
    "Y_train = X_train['has_product_click'].astype(int)\n",
    "X_train = X_train.drop('has_product_click', axis=1)\n",
    "\n",
    "Y_test = X_test['has_product_click'].astype(int)\n",
    "X_test = X_test.drop('has_product_click', axis=1)\n",
    "X_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, auc, confusion_matrix, f1_score\n",
    "\n",
    "def metrics(model):\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    # print(f\"{Y_pred.shape} - {Y_test.shape}\")\n",
    "    matrix = confusion_matrix(Y_test, Y_pred)\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"{matrix}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    if isinstance(model, DecisionTreeClassifier):\n",
    "        featureImportances = model.feature_importances_\n",
    "    elif isinstance(model, LogisticRegression):\n",
    "        featureImportances = model.coef_[0]\n",
    "\n",
    "    features = X_train.columns\n",
    "    features = list(zip(features, featureImportances))\n",
    "    features.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i in range(10):\n",
    "        print(f\"{features[i][0]}:\\t{round(features[i][1], 4)}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=200,\n",
    "    random_state = RANDOM_STATE\n",
    ")\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "metrics(lr)\n",
    "\n",
    "dtc = DecisionTreeClassifier(\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "dtc.fit(X_train, Y_train)\n",
    "metrics(dtc)\n",
    "\n",
    "# rfc = RandomForestClassifier(\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "# rfc.fit(X_train, Y_train)\n",
    "# metrics(rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['filter_string'].dropna(axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise-Ranking-Faire-Puya.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
